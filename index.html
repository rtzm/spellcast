<!DOCTYPE html>
<html>
<head>
	<title>Spellcast</title>
	<script type="text/javascript" src="public/javascripts/vendor/jsfeat-min.js"></script>
	<script type="text/javascript" src="public/javascripts/vendor/adapter-latest.js"></script>
	<script src='https://cdn.rawgit.com/naptha/tesseract.js/1.0.10/dist/tesseract.js'></script>
	<script type="module" src="public/javascripts/classes/Spellcast.js"></script>
	<link rel='stylesheet' href='public/stylesheets/style.css' />
</head>
<body>
<header>
	<h1>Spellcast, v0.1.1</h1>
</header>
<div id="glyph-container">
	<canvas id="glyph" width="480" height="320">Your browser does not support HTML5</canvas>
	<canvas id="reticle" width="480" height="320"></canvas>
</div>
<div id="controls">
	<button id="video-control">Start</button>
</div>
<div id="instructions">Press the <strong>Start</strong> button to start reading in camera data. Then either click your mouse or (if on touch device) touch within the box above to begin writing. When you're done, click <strong>Stop</strong>, and your writing will attempt to be transcribed below.</div>
<div id="text-output"></div>

<aside id="about">
	<h2>About</h2>

	<div>This project uses an algorithm to turn video from smart phones into lines drawn on the screen. It then tries to read the symbol you've just drawn with your phone and puts that down on the screen too. The idea is that it sort of turns your phone into a wand that you can use to trace computer-readable symbols which can then be used maybe for a game, for remote input, or whatever.</div>

	<div>All of the video and image processing happens on your phone, so no video or image data is sent over any networks. Only the line drawing that you've drawn is sent over a network. Because this relies so heavily on the technology in your browser, it might not work on some older or unsupported mobile browsers. This project is, obviously, currently under development.</div>

	<div>When you click the Start button, the algorithm begins reading the images from your camera into a canvas element. It then finds the best points for analysis in the image using YAPE06 corner detection, and reads those corners into a frame-by-frame analysis called Lukas-Kanade optical flow. (Both the corner detection and the optical flow analysis are supplied by a library called <a href="https://inspirit.github.io/jsfeat/">jsfeat</a>). This gives the general flow of 100 or so points in the image, which can be averaged to give the overall directional movement of the camera. This is then read back into a canvas element on the screen as the red line drawing you see. When you click the Stop button, that drawing is processed by an OCR library called <a href="https://github.com/naptha/tesseract.js">Tesseract.js</a>, which returns the first (farthest to the left) symbol that it can read.</div>
</about>

</body>
</html>


